{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from Dataset import Dataset, ELM, device\n",
    "from torch.utils.data import DataLoader\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = loadmat('data_training_reactor_pol.mat')\n",
    "test = loadmat('data_validation_reactor_pol.mat')\n",
    "\n",
    "y_train = 0.0001*(train['NAMW'][0]-train['NAMW'][0][0])\n",
    "y_test = 0.0001*(test['NAMW'][0]-test['NAMW'][0][0])\n",
    "\n",
    "x_train = np.concatenate((100*np.concatenate(([[0]], (train['FI'].T[1:]-train['FI'].T[0])), axis=0),\n",
    "                          100*np.concatenate(([[0], [0]], (train['FI'].T[2:]-train['FI'].T[0])), axis=0),\n",
    "                          np.concatenate(([0], y_train[1:]), axis=0).reshape(-1, 1),\n",
    "                          np.concatenate(([0, 0], y_train[2:]), axis=0).reshape(-1, 1)), axis=1)\n",
    "\n",
    "x_test = np.concatenate((100*np.concatenate(([[0]], (test['FI'].T[1:]-test['FI'].T[0])), axis=0),\n",
    "                         100*np.concatenate(([[0], [0]], (test['FI'].T[2:]-test['FI'].T[0])), axis=0),\n",
    "                         np.concatenate(([0], y_test[1:]), axis=0).reshape(-1, 1),\n",
    "                         np.concatenate(([0, 0], y_test[2:]), axis=0).reshape(-1, 1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Dataset(x_train, y_train)\n",
    "testset = Dataset(x_test, y_test)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=256, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=256, shuffle=False)\n",
    "\n",
    "activation = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ELM(4, 50, 1).to(device)\n",
    "\n",
    "V = activation(model.fc1.bias.data.reshape(-1, 1) + model.fc1.weight.data @ trainset[:][0].T.to(device))\n",
    "H = torch.concatenate([torch.ones(1, len(trainset)).to(device), V.to(device)], dim=0).T\n",
    "T = trainset[:][1].reshape(1, -1).T.to(device)\n",
    "W2 = torch.linalg.pinv(H) @ T.reshape(1, -1, 1)\n",
    "model.fc2.bias.data, model.fc2.weight.data = W2[0][0], W2[0][1:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infGain(model, loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.reshape(-1, 4).to(device), y.reshape(-1, 1).to(device)\n",
    "        preds = model(x).to(device)\n",
    "        loss += torch.norm(preds - y) \n",
    "    return loss\n",
    "\n",
    "def prune(model, loader):\n",
    "    inf = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(model.fc1.out_features):\n",
    "            fc1_weight_temp = copy.deepcopy(model.fc1.weight.data[i])\n",
    "            fc1_bias_temp = copy.deepcopy(model.fc1.bias.data[i])\n",
    "            fc2_weight_temp = copy.deepcopy(model.fc2.weight.data[:,i])\n",
    "            model.fc1.weight.data[i] = 0\n",
    "            model.fc1.bias.data[i] = 0\n",
    "            model.fc2.weight.data[:,i] = 0\n",
    "            inf.append(infGain(model, loader))\n",
    "            model.fc1.weight.data[i] = fc1_weight_temp\n",
    "            model.fc1.bias.data[i] = fc1_bias_temp\n",
    "            model.fc2.weight.data[:,i] = fc2_weight_temp\n",
    "        neuron_to_prune = np.argmin(torch.tensor(inf).cpu().detach().numpy())\n",
    "        pruned_model = ELM(1, model.fc1.out_features-1, 1)\n",
    "        pruned_model.fc1.weight.data = torch.cat([model.fc1.weight.data[:neuron_to_prune], model.fc1.weight.data[neuron_to_prune+1:]])\n",
    "        pruned_model.fc1.bias.data = torch.cat([model.fc1.bias.data[:neuron_to_prune], model.fc1.bias.data[neuron_to_prune+1:]])\n",
    "        pruned_model.fc2.weight.data = torch.cat([model.fc2.weight.data[:,:neuron_to_prune],model.fc2.weight.data[:,neuron_to_prune+1:]], dim=1)\n",
    "    return pruned_model\n",
    "\n",
    "# for _ in range(2):\n",
    "#     model = prune(model, testloader).to(device)\n",
    "\n",
    "# V = activation(model.fc1.bias.data.reshape(-1, 1) + model.fc1.weight.data @ trainset[:][0].T.to(device))\n",
    "# H = torch.concatenate([torch.ones(1, len(trainset)).to(device), V.to(device)], dim=0).T\n",
    "# T = trainset[:][1].reshape(1, -1).T.to(device)\n",
    "# W2 = torch.linalg.pinv(H) @ T.reshape(1, -1, 1)\n",
    "# model.fc2.bias.data, model.fc2.weight.data = W2[0][0], W2[0][1:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mfc2\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata, model\u001b[38;5;241m.\u001b[39mfc2\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m W2[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], W2[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m5\u001b[39m\u001b[38;5;241m*\u001b[39mj\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.01\u001b[39m), \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m---> 19\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mprune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     20\u001b[0m V \u001b[38;5;241m=\u001b[39m activation(model\u001b[38;5;241m.\u001b[39mfc1\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m model\u001b[38;5;241m.\u001b[39mfc1\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m@\u001b[39m trainset[:][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m     21\u001b[0m H \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcatenate([torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(trainset))\u001b[38;5;241m.\u001b[39mto(device), V\u001b[38;5;241m.\u001b[39mto(device)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n",
      "Cell \u001b[1;32mIn[20], line 21\u001b[0m, in \u001b[0;36mprune\u001b[1;34m(model, loader)\u001b[0m\n\u001b[0;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39mfc1\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mfc2\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata[:,i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 21\u001b[0m inf\u001b[38;5;241m.\u001b[39mappend(\u001b[43minfGain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mfc1\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata[i] \u001b[38;5;241m=\u001b[39m fc1_weight_temp\n\u001b[0;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mfc1\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata[i] \u001b[38;5;241m=\u001b[39m fc1_bias_temp\n",
      "Cell \u001b[1;32mIn[20], line 6\u001b[0m, in \u001b[0;36minfGain\u001b[1;34m(model, loader)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m      5\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 6\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(preds \u001b[38;5;241m-\u001b[39m y) \n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\ASamek.ERP\\Desktop\\Pliki\\Studia\\Inzynierka\\Dynamic\\Dataset.py:26\u001b[0m, in \u001b[0;36mELM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x)\n\u001b[0;32m     25\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(x)\n\u001b[1;32m---> 26\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "max_train_error = []\n",
    "min_train_error = []\n",
    "max_test_error = []\n",
    "min_test_error = []\n",
    "num_neurons = 200\n",
    "for j in range(1, num_neurons+1):\n",
    "    print(j)\n",
    "    train_error = []\n",
    "    test_error = []\n",
    "    for i in range(8):\n",
    "        model = ELM(4, 5*j, 1).to(device)\n",
    "        V = activation(model.fc1.bias.data.reshape(-1, 1) + model.fc1.weight.data @ trainset[:][0].T.to(device))\n",
    "        H = torch.concatenate([torch.ones(1, len(trainset)).to(device), V.to(device)], dim=0).T\n",
    "        T = trainset[:][1].reshape(1, -1).T.to(device)\n",
    "        W2 = torch.linalg.pinv(H) @ T.reshape(1, -1, 1)\n",
    "        model.fc2.bias.data, model.fc2.weight.data = W2[0][0], W2[0][1:].T\n",
    "        for _ in range(max(int(5*j*0.01), 1)):\n",
    "            model = prune(model, testloader).to(device)\n",
    "        V = activation(model.fc1.bias.data.reshape(-1, 1) + model.fc1.weight.data @ trainset[:][0].T.to(device))\n",
    "        H = torch.concatenate([torch.ones(1, len(trainset)).to(device), V.to(device)], dim=0).T\n",
    "        T = trainset[:][1].reshape(1, -1).T.to(device)\n",
    "        W2 = torch.linalg.pinv(H) @ T.reshape(1, -1, 1)\n",
    "        model.fc2.bias.data, model.fc2.weight.data = W2[0][0], W2[0][1:].T\n",
    "        train_error.append((model(trainset[:][0].clone().detach().reshape(-1, 4).to(device))-trainset[:][1].reshape(-1, 1).to(device)).reshape(-1).pow(2).mean())\n",
    "        test_error.append((model(testset[:][0].clone().detach().reshape(-1, 4).to(device))-testset[:][1].reshape(-1, 1).to(device)).reshape(-1).pow(2).mean())\n",
    "    max_train_error.append(max(train_error).item())\n",
    "    min_train_error.append(min(train_error).item())\n",
    "    max_test_error.append(max(test_error).item())\n",
    "    min_test_error.append(min(test_error).item())\n",
    "ax[0].plot([5*i+5 for i in range(num_neurons)], max_train_error, 'r', label='Błąd maksymalny')\n",
    "ax[0].plot([5*i+5 for i in range(num_neurons)], min_train_error, 'b', label='Błąd minimalny')\n",
    "ax[0].set_ylabel('Błąd średniokwadratowy zbioru uczącego')\n",
    "ax[0].set_xlabel('Liczba neuronów')\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].grid()\n",
    "ax[0].legend(loc='upper right')\n",
    "ax[1].plot([5*i+5 for i in range(num_neurons)], max_test_error, 'r', label='Błąd maksymalny')\n",
    "ax[1].plot([5*i+5 for i in range(num_neurons)], min_test_error, 'b', label='Błąd minimalny')\n",
    "ax[1].set_ylabel('Błąd średniokwadratowy zbioru weryfikującego')\n",
    "ax[1].set_xlabel('Liczba neuronów')\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].grid()\n",
    "ax[1].legend(loc='upper right')\n",
    "plt.show()\n",
    "from decimal import Decimal\n",
    "for i, error in enumerate(min_test_error):\n",
    "    if i+1 in [1, 2, 10, 20, 100, 200]:\n",
    "        print(f'{Decimal(error):.2e}', end=' & ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train error: {(model(trainset[:][0].clone().detach().reshape(-1, 4).to(device))-trainset[:][1].reshape(-1, 1).to(device)).reshape(-1).pow(2).mean()}')\n",
    "print(f'Test error: {(model(testset[:][0].clone().detach().reshape(-1, 4).to(device))-testset[:][1].reshape(-1, 1).to(device)).reshape(-1).pow(2).mean()}')\n",
    "plt.plot(y_test)\n",
    "plt.plot(model(torch.tensor(x_test).reshape(-1, 4).to(device)).cpu().detach().numpy(), 'r--')\n",
    "plt.legend(['Dane weryfikujące', 'Model'], loc='upper right')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([np.min(y_test), np.max(y_test)], [np.min(y_test), np.max(y_test)])\n",
    "plt.plot(y_test, model(torch.tensor(x_test).reshape(-1, 4).to(device)).cpu().detach().numpy(), '.', markersize=1)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
